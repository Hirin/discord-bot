"""
Document Upload Views - UI components for document upload flow
"""

import asyncio
import logging

import discord

from services import llm, slide_cache
from services.prompts import MEETING_VLM_PROMPT, LECTURE_VLM_PROMPT
from utils.document_utils import pdf_to_images, validate_attachment

logger = logging.getLogger(__name__)


class DocumentPromptView(discord.ui.View):
    """Yes/No buttons for document upload prompt"""

    def __init__(self):
        super().__init__(timeout=30)  # 30s timeout for button click
        self.wants_doc = None
        self.doc_interaction = None

    @discord.ui.button(label="‚úÖ C√≥", style=discord.ButtonStyle.success)
    async def yes_button(
        self, interaction: discord.Interaction, button: discord.ui.Button
    ):
        self.wants_doc = True
        self.doc_interaction = interaction
        await interaction.response.send_message(
            "üìé **Upload file PDF** trong 90s...\n"
            "_(G·ª≠i file v√†o channel n√†y)_",
            ephemeral=True,
        )
        self.stop()

    @discord.ui.button(label="‚ùå Kh√¥ng", style=discord.ButtonStyle.secondary)
    async def no_button(
        self, interaction: discord.Interaction, button: discord.ui.Button
    ):
        self.wants_doc = False
        await interaction.response.defer()
        self.stop()


async def prompt_for_document(
    interaction: discord.Interaction,
    bot,
    guild_id: int,
    mode: str = "meeting",
) -> str | None:
    """
    Prompt user for optional document upload and extract slide content.
    
    Args:
        interaction: Discord interaction (must be deferred)
        bot: Discord bot instance
        guild_id: Guild ID for API key
        mode: "meeting" or "lecture" - determines extraction focus
        
    Returns:
        Extracted slide content text or None
    """
    # Get VLM prompt for cache key
    vlm_prompt = LECTURE_VLM_PROMPT if mode == "lecture" else MEETING_VLM_PROMPT
    
    # Send prompt with buttons
    view = DocumentPromptView()
    prompt_msg = await interaction.followup.send(
        "üìé **C√≥ b·ªï sung t√†i li·ªáu?**\n"
        "Tr√≠ch xu·∫•t n·ªôi dung slides ƒë·ªÉ summary chi ti·∫øt h∆°n",
        view=view,
        ephemeral=True,
    )

    # Wait for button click or timeout
    await view.wait()

    # Clean up prompt message
    try:
        await prompt_msg.delete()
    except Exception:
        pass

    if not view.wants_doc:
        return None

    # Wait for file upload
    def check(m):
        return (
            m.author.id == interaction.user.id
            and m.channel.id == interaction.channel.id
            and m.attachments
        )

    try:
        msg = await bot.wait_for("message", check=check, timeout=90)
        attachment = msg.attachments[0]
        filename = attachment.filename

        # Validate file
        is_valid, error = validate_attachment(attachment)
        if not is_valid:
            await interaction.followup.send(f"‚ùå {error}", ephemeral=True)
            return None
        
        # Check cache BEFORE downloading (save bandwidth)
        cached_content = slide_cache.get_cached_slide_content(filename, vlm_prompt)
        if cached_content:
            # Delete message immediately
            try:
                await msg.delete()
            except Exception:
                pass
            
            await interaction.followup.send(
                f"‚úÖ S·ª≠ d·ª•ng cache ({len(cached_content)} chars) ‚ö°",
                ephemeral=True
            )
            return cached_content

        # Download file - create editable status message
        status_msg = await interaction.followup.send(
            "‚è≥ ƒêang t·∫£i t√†i li·ªáu...", 
            ephemeral=True,
            wait=True
        )
        file_bytes = await attachment.read()
        
        # Delete user's message with attachment immediately after download
        try:
            await msg.delete()
        except Exception:
            pass

        # Update status for processing
        try:
            await status_msg.edit(content="‚è≥ ƒêang x·ª≠ l√Ω t√†i li·ªáu...")
        except Exception:
            pass

        # Process file (convert PDF to images)
        images = pdf_to_images(file_bytes)

        if not images:
            try:
                await status_msg.edit(content="‚ùå Kh√¥ng th·ªÉ ƒë·ªçc PDF")
            except Exception:
                pass
            return None

        # Update status for VLM extraction
        try:
            await status_msg.edit(content="‚è≥ ƒêang tr√≠ch xu·∫•t n·ªôi dung slides (2-5 ph√∫t)...")
        except Exception:
            pass

        # Extract slide content using Vision model
        slide_content = await llm.extract_slide_content(images, guild_id, mode=mode)

        # Check for VLM error
        if slide_content and slide_content.startswith("‚ö†Ô∏è VLM"):
            # Import ErrorRetryView here to avoid circular import
            from cogs.meeting.modals import ErrorRetryView
            
            # Create retry callback
            async def retry_vlm(retry_interaction, **kwargs):
                try:
                    new_content = await llm.extract_slide_content(
                        kwargs["images"],
                        kwargs["guild_id"],
                        mode=kwargs.get("mode", "meeting")
                    )
                    if new_content and not new_content.startswith("‚ö†Ô∏è VLM"):
                        slide_cache.save_slide_content_cache(
                            kwargs["filename"], kwargs["vlm_prompt"], new_content
                        )
                        await retry_interaction.followup.send(
                            f"‚úÖ Retry th√†nh c√¥ng! ({len(new_content)} chars)",
                            ephemeral=True
                        )
                        # Can't return content, but it's cached now
                    else:
                        await retry_interaction.followup.send(
                            f"‚ùå Retry failed: {new_content or 'No content'}",
                            ephemeral=True
                        )
                except Exception as err:
                    await retry_interaction.followup.send(f"‚ùå Retry error: {err}", ephemeral=True)
            
            retry_args = {
                "images": images,
                "guild_id": guild_id,
                "mode": mode,
                "filename": filename,
                "vlm_prompt": vlm_prompt,
            }
            view = ErrorRetryView(retry_vlm, retry_args)
            
            try:
                await status_msg.edit(content=f"‚ùå VLM Error:\n{slide_content}", view=view)
            except Exception:
                pass
            return None  # Return None so summarize proceeds without slides

        # Save to cache and update status
        if slide_content:
            slide_cache.save_slide_content_cache(filename, vlm_prompt, slide_content)
            try:
                await status_msg.edit(
                    content=f"‚úÖ ƒê√£ tr√≠ch xu·∫•t slides ({len(slide_content)} chars) - cache 24h"
                )
            except Exception:
                pass

        return slide_content

    except asyncio.TimeoutError:
        await interaction.followup.send(
            "‚è∞ Timeout - ti·∫øp t·ª•c kh√¥ng c√≥ t√†i li·ªáu",
            ephemeral=True,
        )
        return None
    except Exception as e:
        logger.exception("Error processing document")
        await interaction.followup.send(
            f"‚ùå L·ªói x·ª≠ l√Ω t√†i li·ªáu: {str(e)[:50]}",
            ephemeral=True,
        )
        return None
